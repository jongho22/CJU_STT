{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporary directory: /tmp\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import torch\n",
    "from pydub import AudioSegment\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"|1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import base64\n",
    "from io import *\n",
    "import struct\n",
    "import numpy as np\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_wav_header(binary_data):\n",
    "    # WAV 파일 헤더 구조에 맞게 필드를 읽음\n",
    "  \n",
    "    chunk_id = binary_data[:4]\n",
    "    chunk_size = struct.unpack('<I', binary_data[4:8])[0]\n",
    "    format_str = binary_data[8:12]\n",
    "    subchunk1_id = binary_data[12:16]\n",
    "    subchunk1_size = struct.unpack('<I', binary_data[16:20])[0]\n",
    "    audio_format = struct.unpack('<H', binary_data[20:22])[0]\n",
    "    num_channels = struct.unpack('<H', binary_data[22:24])[0]\n",
    "    sample_rate = struct.unpack('<I', binary_data[24:28])[0]\n",
    "    byte_rate = struct.unpack('<I', binary_data[28:32])[0]\n",
    "    block_align = struct.unpack('<H', binary_data[32:34])[0]\n",
    "    bits_per_sample = struct.unpack('<H', binary_data[34:36])[0]\n",
    "    subchunk2_id = binary_data[36:40]\n",
    "    subchunk2_size = struct.unpack('<I', binary_data[40:44])[0]\n",
    "    \n",
    "\n",
    "    header = {\"Chunk_ID\": chunk_id,\n",
    "      \"Chunk_Size\" : chunk_size,\n",
    "      \"Format\" : format_str,\n",
    "      \"Subchunk1_ID\" : subchunk1_id,\n",
    "      \"Subchunk1_Size\" : subchunk1_size,\n",
    "      \"Audio_Format\" : audio_format,\n",
    "      \"Num_Channels\" : num_channels,\n",
    "      \"Sample_Rate\" : sample_rate,\n",
    "      \"Byte_Rate\" : byte_rate,\n",
    "      \"Block_Align\" : block_align,\n",
    "      \"Bits_Per_Sample\" : bits_per_sample,\n",
    "      \"Subchunk2_ID\" : subchunk2_id,\n",
    "      \"Subchunk2_Size\" : subchunk2_size}\n",
    "    return header \n",
    "\n",
    "def make_header(wav_header, input_data_size) :\n",
    "    chunk_id = wav_header['Chunk_ID']\n",
    "    chunk_size = input_data_size + 44  # 데이터 크기에 추가 정보 크기(46바이트)를 더함\n",
    "    format_str = wav_header['Format']\n",
    "    subchunk1_id = wav_header['Subchunk1_ID']\n",
    "    subchunk1_size = wav_header['Subchunk1_Size']  # 일반적인 값을 사용함\n",
    "    audio_format = wav_header['Audio_Format'] # PCM 포맷\n",
    "    num_channels = wav_header['Num_Channels']  # 스테레오\n",
    "    sample_rate = wav_header['Sample_Rate']  # 예시로 44100Hz\n",
    "    byte_rate = wav_header['Byte_Rate']\n",
    "    block_align = wav_header['Block_Align']    # 채널 수 * 샘플 크기(2바이트)\n",
    "    bits_per_sample = wav_header['Bits_Per_Sample']   # 16비트 PCM 사용\n",
    "    subchunk2_id =  b'data'\n",
    "    subchunk2_size = input_data_size + 44  # 데이터 크기\n",
    "\n",
    "    wav_header = struct.pack('<4sI4s4sIHHIIHH4sI', chunk_id, chunk_size, format_str, subchunk1_id,\n",
    "                            subchunk1_size, audio_format, num_channels, sample_rate, byte_rate,\n",
    "                            block_align, bits_per_sample, subchunk2_id, subchunk2_size)\n",
    "    \n",
    "    return wav_header\n",
    "\n",
    "def STT_module(audio_with_header,model) :\n",
    "    # 임시 파일 생성\n",
    "    temp_file = tempfile.NamedTemporaryFile(suffix='.wav', delete=False)\n",
    "    temp_file.write(audio_with_header)\n",
    "    temp_path = temp_file.name\n",
    "\n",
    "    # STT 실행\n",
    "    result = model.transcribe(temp_path, fp16=False)\n",
    "    print(result['text'])\n",
    "\n",
    "    # 임시 파일 삭제\n",
    "    os.remove(temp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 메인 모델\n",
    "model = whisper.load_model(\"medium\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/home/jongho/바탕화면/테스트 음성파일/\"\n",
    "file_name = \"연제리2.wav\"\n",
    "\n",
    "encode_audio = base64.b64encode(open(f\"{file_path}{file_name}\", \"rb\").read()).decode('utf-8') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "음성파일 헤더 정보 : {'Chunk_ID': b'RIFF', 'Chunk_Size': 543172920, 'Format': b'WAVE', 'Subchunk1_ID': b'fmt ', 'Subchunk1_Size': 16, 'Audio_Format': 1, 'Num_Channels': 2, 'Sample_Rate': 44100, 'Byte_Rate': 176400, 'Block_Align': 4, 'Bits_Per_Sample': 16, 'Subchunk2_ID': b'LIST', 'Subchunk2_Size': 80}\n"
     ]
    }
   ],
   "source": [
    "# 웹 소켓을 통해서 base64 데이터를 수신 받았을때\n",
    "# 바이너리 데이터로 변환\n",
    "decoded_audio = base64.b64decode(encode_audio)\n",
    "\n",
    "# 오디오 데이터에서 헤더정보 추출\n",
    "BINARY_DATA = decoded_audio[:44]\n",
    "audio_signal_data = decoded_audio[44:]\n",
    "\n",
    "wav_header = extract_wav_header(BINARY_DATA)\n",
    "\n",
    "print(\"음성파일 헤더 정보 :\",wav_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "바이너리 데이터 분할 완료 : 55개\n"
     ]
    }
   ],
   "source": [
    "# 분할 사이즈\n",
    "SPLIT_SIZE = 10000000 # 10MB\n",
    "# 기본 경로\n",
    "BASE_PATH = \"/home/jongho/Spring_project/CJU_STT/CJU_Web_Application_Services/src/main/webapp/resources/python/result\"\n",
    "# 분할 바이너리 데이터 리스트\n",
    "split_data = []\n",
    "\n",
    "for i in range(0, len(audio_signal_data), SPLIT_SIZE):\n",
    "    split_data.append(audio_signal_data[i:i+SPLIT_SIZE])\n",
    "\n",
    "print(f\"바이너리 데이터 분할 완료 : {len(split_data)}개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jongho/.local/lib/python3.8/site-packages/torch/functional.py:515: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:590.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore\n",
      "/home/jongho/.local/lib/python3.8/site-packages/whisper/decoding.py:750: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  [t[self.sample_begin : (t == tokenizer.eot).nonzero()[0, 0]] for t in s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 해수 받으면 초기화하고 2개 대사 검거를 한 다음에 초기화하고 다음 조사를 위해서 세팅하는 거 네 개거든요 8개씩 해서 32개 하시면 되고 충전하고 배포하는 거 해주시면 되고요 조사 물품도 곤약에 물품 수정에 맞게 배포해주시면 되세요 그래서 지금 아까 조사 일정이 따라서 저희가 배포를 하고 다음 날부터 착용을 하게 하잖아요 착용하는 날에 문자 알림을 보내실 거죠 그리고 중간연검 3일째 그리고 마지막 회수하는 시절에 한 3번 정도 알림을 보내시는 걸로 알고 있고 그리고 저희가 조사원하고 업무를 어떻게 해야 될지를 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아 아\n",
      " 프로토컬을 이렇게 만드셔가지고 그걸 하나 딱 표준화해서 만들어놓으면 좋을 것 같거든요 그래서 저희가 오늘 말씀드린 내용으로 뭔가 만들어서 보내주시면 네, 확정해서 진행하면 될 것 같아요 교육이나 뭐 이런 거 할 때도 딱 그렇게 진행하면 될 것 같아서 네, 그리고 3프레이지에서는 이제 교상자 확인하고 관리 분단자를 지정해야지 되는 거 그... 지금... 저희가 침이 내 팀이라고 했잖아요 그러면은 담당하시는 분은 팀별로 배공을 하실 건가요? 아니면 한 분이 내 팀을 다 총괄하신 건가요? 어, 네 네, 그게 팀 입성이 되어 있고 거기에 또 총괄하는 또 이런 거 있고 아, 팀별로도 배공을 하시는 거예요? 네, 네 네, 네 네, 네 그러면은 저희 쪽에도 그 내 팀의 명단을 해서 매칭해서 네, 네 만들어주시면 좋은 것 같습니다\n",
      " 1일차, 3일차, 7일차에 많이 하는 거 해주시면 되고요. 저희가 이제 대상자한테 연락처를 드릴 건데 비상 상황이나 이런 분들 연락을 받으셔야 되거든요. 네. 그래서 혹시 24시간 가능하신지? 가능합니다. 그래서 연락처는 여기 저희가 운동일지에 연락처 하나 넣을 거라서 네. 가능한 연락처? 네. 연락처 하나 넣어주시면 되고 저희도 넣을 건데 저희는 이제 업무 시간 대응이 가능하니까 네. 고부 하나 해주시면 됩니다. 수출 괜찮아? 네, 괜찮습니다. 괜찮습니다. 네. 20일 하시면 됩니다. 조사 완료 단계에서는요. 저희가 이제 횟수 잘 돼야 하시고요. 저희가 실태상에 지금 하루 끝나고 10일이 지났는데도 아직 횟수 별 날이 안 된다 하면 알람이 뜨겠다고 하거든요. 그래서 회수 안 됐을 때\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(split_data)) :\n",
    "    # WAV 파일 헤더 정보 생성\n",
    "    audio_with_header = make_header(wav_header, len(split_data[i])) + split_data[i]\n",
    "   \n",
    "    # API 처리 구간\n",
    "    STT_module(audio_with_header, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
